{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this demonstration, we explore the implementation of three key techniques in PyTorch to improve the stability and performance of a neural network during training:\n",
        "* **Gradient clipping** is used to prevent the exploding gradient problem by capping the gradients during backpropagation\n",
        "* **Weight regularization** (L2 regularization) is applied via the optimizer to avoid overfitting by penalizing large weights\n",
        "* **Batch normalization** is incorporated to normalize the input layer by adjusting and scaling the activations.\n",
        "\n",
        "These techniques are instrumental in ensuring that our model trains effectively and generalizes well to new data."
      ],
      "metadata": {
        "id": "wLmrabNAkGzY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n0YWmZUzkFKr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming we have a simple neural network for demonstration purposes:\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=100)\n",
        "        self.fc1 = nn.Linear(100, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch_norm(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "607vydOykIEA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "model = SimpleNet()"
      ],
      "metadata": {
        "id": "ZY_BCIu4kNOF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use weight decay for L2 regularization\n",
        "weight_decay = 1e-5\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "X9JcMQg1kQ9J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy inputs and outputs for demonstration\n",
        "inputs = torch.randn(64, 100)\n",
        "targets = torch.randint(0, 10, (64,))\n"
      ],
      "metadata": {
        "id": "MxAGdS29kUN_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 5\n",
        "clip_value = 1.0  # Gradient clipping threshold"
      ],
      "metadata": {
        "id": "yQRN1zugkXtW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMMl3Bz_ka7t",
        "outputId": "4e1cc884-1be8-47a3-97de-1f53633b0978"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 2.324849843978882\n",
            "Epoch 2/5, Loss: 2.290389060974121\n",
            "Epoch 3/5, Loss: 2.256732225418091\n",
            "Epoch 4/5, Loss: 2.2237589359283447\n",
            "Epoch 5/5, Loss: 2.191350221633911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1MNpOmy5ke6_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}